# Portfolio
<script src="https://www.retainable.io/assets/retainable/rss-embed/retainable-rss-embed.js"></script>
---

<style>
    .image-with-shadow {
        box-shadow: 0px 1px 6px rgba(63, 69, 81, 0.16);
        border-radius: 8px;
    }

    .image-container {
    display: flex; /* Or use "display: grid;" for a grid layout */
    justify-content: space-between; /* Adjust as needed */
    }

    .image-container img {
        width: 48%; /* Adjust the width as needed to fit both images side by side */
        height: auto; /* To maintain aspect ratio */
    }
</style>

## Large Language Models (LLMs)

### 1. IndoBERT Sentiment Analysis: Sentiment Analysis with IndoBERT Fine-tuning and IndoNLU SmSA Dataset
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/IndoBERT-WebApp-Sentiment-Analysis-using-Streamlit-for-Indonesian){:target="_blank"}
[![Stars](https://img.shields.io/github/stars/crypter70/IndoBERT-WebApp-Sentiment-Analysis-using-Streamlit-for-Indonesian?style=social)](https://github.com/crypter70/IndoBERT-WebApp-Sentiment-Analysis-using-Streamlit-for-Indonesian){:target="_blank"}

<div style="text-align: justify">
    <strong>Description:</strong>
        <br>
        This project contains the end-to-end development of LLM text classification model by fine-tuning pre-trained IndoBERT model using IndoNLU SmSA dataset. This model is able to predict sentence sentiment into several categories namely positive, neutral, and negative.
        <br>
        <br>
    <div><strong>Tech Stack: </strong>Transformers, PyTorch, Pillow, and Streamlit</div>
    <div><strong>Streamlit: </strong><a href="https://crypter70-indobert-webapp-sentiment-analysis-using-s-app-kli3uq.streamlit.app/" target="_blank">Sentiment Analysis App</a></div>
    <div><strong>Fine-tuning: </strong><a href="https://github.com/crypter70/Sentiment-Analysis-with-IndoBERT-Fine-tuning-and-IndoNLU-SmSA-Dataset" target="_blank">Fine-tuning GitHub Repository</a></div>
    <div><strong>HuggingFace: </strong><a href="https://huggingface.co/crypter70/IndoBERT-Sentiment-Analysis" target="_blank">IndoBERT-Sentiment-Analysis</a></div>
    <br>
</div>

<center>
    <iframe src="https://crypter70-indobert-webapp-sentiment-analysis-using-s-app-ka6hlg.streamlit.app?embed=true" style="height: 450px; width: 100%;" frameBorder="0"></iframe>
</center>
---

### 2. Text Summarization using LangChain and BART Large CNN
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/Text-Summarization-using-LangChain-and-BART-Large-CNN){:target="_blank"}
[![Stars](https://img.shields.io/github/stars/crypter70/Text-Summarization-using-LangChain-and-BART-Large-CNN?style=social)](https://github.com/crypter70/Text-Summarization-using-LangChain-and-BART-Large-CNN){:target="_blank"}

<div style="text-align: justify">
    <strong>Description:</strong>
        <br>
        This project features the development and implementation of an advanced text summarization system using LangChain and BART-Large-CNN. 
        This project allows users to summarize long text entered in the app into a few sentences.
        <br>
        <br>
    <div><strong>Tech Stack: </strong>LangChain, HuggingFaceHub, and Streamlit</div>
    <div><strong>Streamlit: </strong><a href="https://crypter70-text-summarization-using-langchain-and-bar-app-cqua0w.streamlit.app" target="_blank">Text Summarization App</a></div>
    <br>
</div>

<center>
    <iframe src="https://crypter70-text-summarization-using-langchain-and-bar-app-cqua0w.streamlit.app?embed=true" style="height: 450px; width: 100%;" frameBorder="0"></iframe>
</center>
---

### 1. Bank Customer Churn Prediction
[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](https://github.com/crypter70/Bank-Customer-Churn-Prediction/blob/main/Bank%20Customer%20Churn%20Prediction.ipynb){:target="_blank"}
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/Bank-Customer-Churn-Prediction){:target="_blank"}
[![Stars](https://img.shields.io/github/stars/crypter70/Bank-Customer-Churn-Prediction?style=social)](https://github.com/crypter70/Bank-Customer-Churn-Prediction){:target="_blank"}
[![Article](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@crypter70/bank-customer-churn-prediction-using-machine-learning-514516ecf82e){:target="_blank"}

<div style="text-align: justify">
    <strong>Objective:</strong>
        <br>
        This project aims to uncover deep insights about bank customers from data and build a well-performing churn prediction model. The project focuses on transforming data into valuable information and developing a high-performance model for churn prediction of bank customers.
        <br>
        <br>
    <strong>Article:</strong>
    <br>
    <p>Read the article here (<a href="https://medium.com/@crypter70/bank-customer-churn-prediction-using-machine-learning-514516ecf82e" target="_blank">Medium Article</a>) </p>
</div>

<center>
    <img src="images/bank-customer-churn/model.png" class="image-with-shadow">
    <br>
    <br>
    <div class="image-container">
        <img src="images/bank-customer-churn/confusion-matrix.png" class="image-with-shadow">
        <img src="images/bank-customer-churn/rocauc-curve.png" class="image-with-shadow">
    </div>
        <div style="position: relative; width: 100%; height: 0; padding-top: 56.2500%;
        padding-bottom: 0; box-shadow: 0 2px 8px 0 rgba(63,69,81,0.16); margin-top: 1.6em; margin-bottom: 0.9em; overflow: hidden;
        border-radius: 8px; will-change: transform;">
        <iframe loading="lazy" style="position: absolute; width: 100%; height: 100%; top: 0; left: 0; border: none; padding: 0;margin: 0;"
            src="https:&#x2F;&#x2F;www.canva.com&#x2F;design&#x2F;DAFn-oQ3tJo&#x2F;view?embed" allowfullscreen="allowfullscreen" allow="fullscreen">
        </iframe>
        </div>
        <a href="https:&#x2F;&#x2F;www.canva.com&#x2F;design&#x2F;DAFn-oQ3tJo&#x2F;view?utm_content=DAFn-oQ3tJo&amp;utm_campaign=designshare&amp;utm_medium=embeds&amp;utm_source=link" target="_blank" rel="noopener">Bank Customer Churn Prediction</a> by Yosafat
    <br>
    <br>
</center>
---

### 2. Electric Vehicle Type Classification
[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](https://github.com/crypter70/Electric-Vehicle-Type-Classification/blob/main/Electric%20Vehicle%20Type%20Classification.ipynb){:target="_blank"}
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/Electric-Vehicle-Type-Classification){:target="_blank"}
[![Stars](https://img.shields.io/github/stars/crypter70/Electric-Vehicle-Type-Classification?style=social)](https://github.com/crypter70/Electric-Vehicle-Type-Classification){:target="_blank"}
<!-- [![Forks](https://img.shields.io/github/forks/crypter70/Stocks-Prediction?style=social)](https://github.com/crypter70/Stocks-Prediction) -->
[![Article](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@crypter70/classification-of-electric-vehicle-types-using-machine-learning-7768f6293603){:target="_blank"}

<div style="text-align: justify">
    <strong>Objective:</strong>
        <br>
        This project aims to uncover deep electric vehicle insights from data and build a well-performing electric vehicle type classification model. It focuses on turning data into valuable information and developing a high-performance model for electric vehicle type classification.
        <br>
        <br>
    <strong>Article:</strong>
    <br>
    <p>Read the article here (<a href="https://medium.com/@crypter70/classification-of-electric-vehicle-types-using-machine-learning-7768f6293603" target="_blank">Medium Article</a>) </p>
</div>

<center>
    <img src="images/electric-vehicle-type/models-selection.png" class="image-with-shadow">
    <br>
    <br>
    <div class="image-container">
        <img src="images/electric-vehicle-type/cf.png" class="image-with-shadow">
        <img src="images/electric-vehicle-type/roc-auc-curve.png" class="image-with-shadow">
    </div>
    <!-- <br>
    <img src="images/electric-vehicle-type/cf.png" class="image-with-shadow" width="90%" height="90%">
    <br>
    <br>
    <img src="images/electric-vehicle-type/roc-auc-curve.png" class="image-with-shadow" width="90%" height="90%">
    <br> -->
    <br>
    <img src="images/electric-vehicle-type/feature-importance.png" class="image-with-shadow" width="90%" height="90%">
    <br>
    <br>
</center>
---

### 3. Credit Default Prediction
[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](https://github.com/crypter70/Credit-Default-Classification/blob/main/Credit%20Default%20Classification.ipynb){:target="_blank"}
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/Credit-Default-Classification){:target="_blank"}
[![Stars](https://img.shields.io/github/stars/crypter70/Credit-Default-Classification?style=social)](https://github.com/crypter70/Credit-Default-Classification){:target="_blank"}
<!-- [![Forks](https://img.shields.io/github/forks/crypter70/Stocks-Prediction?style=social)](https://github.com/crypter70/Stocks-Prediction) -->

<div style="text-align: justify">
    <strong>Objective:</strong>
    <br>
    This project aims to uncover deep credit insights from data and build the best default credit classification model. It focuses on transforming valuable information and developing high performance models for credit classification.
</div>

<center>
    <br>
    <img src="images/model selection.png" class="image-with-shadow">
    <br>
    <br>
    <img src="images/confusion matrix.png" class="image-with-shadow" width="90%" height="90%">
    <br>
    <br>
    <img src="images/feature importance.png" class="image-with-shadow" width="90%" height="90%">
    <br>
    <br>
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
    <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vSFcLcgoogu3hFxtqEjoJJNCn3tmzibuJhKtXauPxQy6lBXgT0CKxzvB_lojPU92BpankbEQjGzx3dJ/embed?start=false&loop=false&delayms=3000" frameborder="0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    </div>
    <br>
    <br>
</center>
---

### 4. Stocks Prediction
[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](https://github.com/crypter70/Stocks-Prediction/blob/main/Stocks%20Forecasting.ipynb){:target="_blank"}
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/Stocks-Prediction){:target="_blank"}
[![Stars](https://img.shields.io/github/stars/crypter70/Stocks-Prediction?style=social)](https://github.com/crypter70/Stocks-Prediction){:target="_blank"}
<!-- [![Forks](https://img.shields.io/github/forks/crypter70/Stocks-Prediction?style=social)](https://github.com/crypter70/Stocks-Prediction) -->

<div style="text-align: justify">
    <strong>Objective:</strong>
    <br>
    A Machine Learning project to forecast stock prices using the Long-Short Term Memory (LSTM) algorithm. The forecasted stocks consist of 4 stock codes on the Indonesia Stock Exchange (IDX), 2 stocks each in the banking sector, namely BBCA and BBNI, the mining sector, namely ADRO and INDY.
</div>

<center>
    <br>
    <img src="images/stocks1.png"/>
    <br>
    <img src="images/stocks2.png"/>
    <br>
    <img src="images/stocks3.png"/>
    <br>
</center>
---

### 5. Topic Extraction
[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](https://github.com/crypter70/Topic-Extraction/blob/main/Topic%20Extraction.ipynb){:target="_blank"}
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/Topic-Extraction){:target="_blank"}
[![Stars](https://img.shields.io/github/stars/crypter70/Topic-Extraction?style=social)](https://github.com/crypter70/Topic-Extraction){:target="_blank"}
<!-- [![Forks](https://img.shields.io/github/forks/crypter70/Stocks-Prediction?style=social)](https://github.com/crypter70/Stocks-Prediction) -->

<div style="text-align: justify">
    <strong>Objective:</strong>
    <br>
    A Machine Learning NLP project to extract research topics based on publication titles using KeyBERT unsupervised keyword extraction approach.
</div>

<center>
    <img src="images/topic1.png"/>
    <br>
    <img src="images/topic2.png"/>
    <br>
</center>
<br>


---
## Dashboard 
### 1. COVID-19 Cases (Indonesia) Dashboard
<div style="text-align: justify">
    <strong>Objective:</strong>
        <br>
        This project aims to transform raw data into useful information about COVID-19 cases in Indonesia using visualizations on the Tableau dashboard.
        <br>
        <br>
    <strong>Dashboard:</strong>
    <br>
    <p>Open the dashboard here (<a href="https://public.tableau.com/views/COVID-19CasesIndonesia/Dashboard1?:language=en-US&:display_count=n&:origin=viz_share_link">Tableau Dashboard</a>) </p>
</div>

<center>
    <img src="images/covid-19-indonesia/dashboard-1.png"/>
    <br>
    <br>
</center>
---

### 2. Credit Dashboard
<div style="text-align: justify">
    <strong>Objective:</strong>
        <br>
        This project aims to transform raw data into useful information for businesses about credit using visualization on the Looker Studio dashboard.
        <br>
        <br>
    <strong>Dashboard:</strong>
    <br>
    <p>Open the dashboard here (<a href="https://lookerstudio.google.com/u/0/reporting/6b1a0b77-0425-446e-9a92-9288a87f03c3/page/p_mghv1jr16c">Looker Studio Dashboard</a>) </p>
</div>

<center>
    <img src="images/credit/dashboard-1.png"/>
    <br>
    <br>
    <img src="images/credit/dashboard-2.png"/>
    <br>
    <br>
    <img src="images/credit/dashboard-3.png"/>
    <br>
    <br>
</center>
---

### 3. COVID-19 Dashboard
<div style="text-align: justify">
    <strong>Objective:</strong>
        <br>
        This project aims to transform raw data into useful information about COVID-19 cases using visualizations on the Looker Studio dashboard.
        <br>
        <br>
    <strong>Dashboard:</strong>
    <br>
    <p>Open the dashboard here (<a href="https://lookerstudio.google.com/u/0/reporting/f6b45eb1-9d07-4d7d-b432-d106743437ff/page/p_42tl4mcf6c">Looker Studio Dashboard</a>) </p>
</div>

<center>
    <img src="images/covid-19/dashboard-1.png"/>
    <br>
    <br>
</center>


---
## Web Scraping 

### 1. Tokopedia Scraper
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/Tokopedia-Scraper){:target="_blank"}
[![Stars](https://img.shields.io/github/stars/crypter70/Tokopedia-Scraper?style=social)](https://github.com/crypter70/Tokopedia-Scraper){:target="_blank"}
[![Forks](https://img.shields.io/github/forks/crypter70/Tokopedia-Scraper?style=social)](https://github.com/crypter70/Tokopedia-Scraper){:target="_blank"}

<div style="text-align: justify">
    <strong>Objective:</strong>
    <br>
    The program aimed to extract product data from the Tokopedia marketplace website based on specified keywords using web scraping techniques. Selenium with JavaScript-enabled selectors was utilized to extract the data due to the dynamic elements on the website. The extracted data included product name, price, location, rating, number of items sold, and details link, which were essential for data analysis and market research. The data was saved in both CSV and JSON formats for further processing and analysis.
</div>

<center>
    <br>
    <img src="images/tokopedia-scraper.png"/>
    <img src="images/tokped_data.png"/>
    <br>
</center>
---

### 2. Nike Scraper
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/Nike-Scraper){:target="_blank"}
[![Stars](https://img.shields.io/github/stars/crypter70/Nike-Scraper?style=social)](https://github.com/crypter70/Nike-Scraper){:target="_blank"}
<!-- [![Forks](https://img.shields.io/github/forks/crypter70/Tokopedia-Scraper?style=social)](https://github.com/crypter70/Nike-Scraper){:target="_blank"} -->

<div style="text-align: justify">
    <strong>Objective:</strong>
    <br>
    Web Scraper program to extract products data from Nike website using Playwright. Playwright is an open-source Node.js library developed by Microsoft for cross-browser web automation and testing. The data retrieved include product name, category, number of colors, and prices which are then exported into csv and json.
</div>

<center>
    <br>
    <img src="images/nike-scraper.png"/>
    <img src="images/nike-data-1.png"/>
    <br>
</center>
---

### 3. SINTA Scraper
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/SINTA-Scraper){:target="_blank"}
[![Stars](https://img.shields.io/github/stars/crypter70/SINTA-Scraper?style=social)](https://github.com/crypter70/SINTA-Scraper){:target="_blank"}

<div style="text-align: justify">
    <strong>Objective:</strong>
    <br>
    The program aimed to extract university data and publication scores from the SINTA website using Scrapy. The targeted website is static, and the data is not loaded using JavaScript, which makes Scrapy an appropriate choice due to its efficiency and speed in handling static data on websites. The extracted data included relevant data such as the university's name, location, and publication scores. The data was saved in CSV format for further processing and analysis.
</div>

<center>
    <br>
    <img src="images/sinta-scraper.png"/>
    <img src="images/sinta_data.png"/>
    <br>
</center>
---

### 4. LTMPT Scraper
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/LTMPT-Scraper){:target="_blank"}
[![Stars](https://img.shields.io/github/stars/crypter70/LTMPT-Scraper?style=social)](https://github.com/crypter70/LTMPT-Scraper){:target="_blank"}

<div style="text-align: justify">
    <strong>Objective:</strong>
    <br>
    The program aimed to extract data on the top 1000 schools based on UTBK scores in 2022 using Scrapy. The targeted website was a static one, and the data was not loaded using JavaScript. Therefore, Scrapy was an appropriate choice due to its efficiency and speed in handling static data on websites. The program extracted relevant data such as the schools' names, locations, UTBK scores, and other relevant information. The extracted data was useful for analyzing and evaluating the schools' academic performance and ranking. The data was saved in CSV format for further processing and analysis.
</div>

<center>
    <br>
    <img src="images/ltmpt-scraper.png"/>
    <img src="images/ltmpt_data.png"/>
    <br>
</center>


---
## Latest Publication
- [Web Scraping Sederhana Menggunakan Scrapy](https://medium.com/@crypter70/web-scraping-sederhana-menggunakan-scrapy-e1e959a05688)
<br>
- [Bank Customer Churn Prediction using Machine Learning](https://medium.com/@crypter70/bank-customer-churn-prediction-using-machine-learning-514516ecf82e)
<br>
- [Classification of Electric Vehicle Types using Machine Learning](https://medium.com/@crypter70/classification-of-electric-vehicle-types-using-machine-learning-7768f6293603)
<br>

---

<center>Â© 2023 Yosafat. Powered by Jekyll and the Minimal Theme.</center>

