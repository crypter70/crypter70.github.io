# Portfolio
<script src="https://www.retainable.io/assets/retainable/rss-embed/retainable-rss-embed.js"></script>
---

## Data Science


### Electric Vehicle Type Classification
[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](https://github.com/crypter70/Electric-Vehicle-Type-Classification/blob/main/Electric%20Vehicle%20Type%20Classification.ipynb)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/Electric-Vehicle-Type-Classification)
[![Stars](https://img.shields.io/github/stars/crypter70/Electric-Vehicle-Type-Classification?style=social)](https://github.com/crypter70/Electric-Vehicle-Type-Classification)
[![TEST](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)]
<!-- https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white -->

<!-- [![Forks](https://img.shields.io/github/forks/crypter70/Stocks-Prediction?style=social)](https://github.com/crypter70/Stocks-Prediction) -->

<div style="text-align: justify">
    <strong>Objective:</strong>
        <br>
        This project aims to uncover deep electric vehicle insights from data and build a well-performing electric vehicle type classification model. It focuses on turning data into valuable information and developing a high-performance model for electric vehicle type classification.
        <br>
        <br>
    <strong>Article:</strong>
    <br>
    <p>Read the article here (<a href="https://medium.com/@crypter70/classification-of-electric-vehicle-types-using-machine-learning-7768f6293603">Medium Article</a>) </p>
</div>

<center>
    <img src="images/electric-vehicle-type/models-selection.png"/>
    <br>
    <img src="images/electric-vehicle-type/confusion-matrix.png"/>
    <br>
    <img src="images/electric-vehicle-type/roc-auc-curve.png"/>
    <br>
    <img src="images/electric-vehicle-type/feature-importance.png"/>
    <br>
</center>
---

### Credit Default Classification
[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](https://github.com/crypter70/Credit-Default-Classification/blob/main/Credit%20Default%20Classification.ipynb)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/Credit-Default-Classification)
[![Stars](https://img.shields.io/github/stars/crypter70/Credit-Default-Classification?style=social)](https://github.com/crypter70/Credit-Default-Classification)
<!-- [![Forks](https://img.shields.io/github/forks/crypter70/Stocks-Prediction?style=social)](https://github.com/crypter70/Stocks-Prediction) -->

<div style="text-align: justify">
    <strong>Objective:</strong>
    <br>
    This project aims to uncover deep credit insights from data and build the best default credit classification model. It focuses on transforming valuable information and developing high performance models for credit classification.
</div>

<center>
    <br>
    <img src="images/model selection.png"/>
    <br>
    <img src="images/confusion matrix.png"/>
    <br>
    <img src="images/feature importance.png"/>
    <br>
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
    <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vSFcLcgoogu3hFxtqEjoJJNCn3tmzibuJhKtXauPxQy6lBXgT0CKxzvB_lojPU92BpankbEQjGzx3dJ/embed?start=false&loop=false&delayms=3000" frameborder="0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
    </div>

</center>
---

### Stocks Prediction
[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](https://github.com/crypter70/Stocks-Prediction/blob/main/Stocks%20Forecasting.ipynb)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/Stocks-Prediction)
[![Stars](https://img.shields.io/github/stars/crypter70/Stocks-Prediction?style=social)](https://github.com/crypter70/Stocks-Prediction)
<!-- [![Forks](https://img.shields.io/github/forks/crypter70/Stocks-Prediction?style=social)](https://github.com/crypter70/Stocks-Prediction) -->

<div style="text-align: justify">A Machine Learning project to forecast stock prices using the Long-Short Term Memory (LSTM) algorithm. The forecasted stocks consist of 4 stock codes on the Indonesia Stock Exchange (IDX), 2 stocks each in the banking sector, namely BBCA and BBNI, the mining sector, namely ADRO and INDY.</div>

<center>
    <br>
    <img src="images/stocks1.png"/>
    <br>
    <img src="images/stocks2.png"/>
    <br>
    <img src="images/stocks3.png"/>
    <br>
</center>
---

### Topic Extraction
[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](https://github.com/crypter70/Topic-Extraction/blob/main/Topic%20Extraction.ipynb)
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/Topic-Extraction)
[![Stars](https://img.shields.io/github/stars/crypter70/Topic-Extraction?style=social)](https://github.com/crypter70/Topic-Extraction)
<!-- [![Forks](https://img.shields.io/github/forks/crypter70/Stocks-Prediction?style=social)](https://github.com/crypter70/Stocks-Prediction) -->

<div style="text-align: justify">A Machine Learning NLP project to extract research topics based on publication titles using KeyBERT unsupervised keyword extraction approach.</div>


<center>
    <img src="images/topic1.png"/>
    <br>
    <img src="images/topic2.png"/>
    <br>
</center>
<br>
---


## Dashboard 
### Credit Dashboard


### COVID-19 Dashboard
--

## Web Scraping 
### Tokopedia Scraper

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/Tokopedia-Scraper)
[![Stars](https://img.shields.io/github/stars/crypter70/Tokopedia-Scraper?style=social)](https://github.com/crypter70/Tokopedia-Scraper)
[![Forks](https://img.shields.io/github/forks/crypter70/Tokopedia-Scraper?style=social)](https://github.com/crypter70/Tokopedia-Scraper)

<div style="text-align: justify">
The program aimed to extract product data from the Tokopedia marketplace website based on specified keywords using web scraping techniques. Selenium with JavaScript-enabled selectors was utilized to extract the data due to the dynamic elements on the website. The extracted data included product name, price, location, rating, number of items sold, and details link, which were essential for data analysis and market research. The data was saved in both CSV and JSON formats for further processing and analysis.
</div>

<center>
    <br>
    <img src="images/tokopedia-scraper.png"/>
    <img src="images/tokped_data.png"/>
    <br>
</center>
---

### SINTA Scraper
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/SINTA-Scraper)
[![Stars](https://img.shields.io/github/stars/crypter70/SINTA-Scraper?style=social)](https://github.com/crypter70/SINTA-Scraper)


<div style="text-align: justify">
The program aimed to extract university data and publication scores from the SINTA website using Scrapy. The targeted website is static, and the data is not loaded using JavaScript, which makes Scrapy an appropriate choice due to its efficiency and speed in handling static data on websites. The extracted data included relevant data such as the university's name, location, and publication scores. The data was saved in CSV format for further processing and analysis.
</div>

<center>
    <br>
    <img src="images/sinta-scraper.png"/>
    <img src="images/sinta_data.png"/>
    <br>
</center>
---

### LTMPT Scraper
[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/crypter70/LTMPT-Scraper)
[![Stars](https://img.shields.io/github/stars/crypter70/LTMPT-Scraper?style=social)](https://github.com/crypter70/LTMPT-Scraper)

<div style="text-align: justify">
The program aimed to extract data on the top 1000 schools based on UTBK scores in 2022 using Scrapy. The targeted website was a static one, and the data was not loaded using JavaScript. Therefore, Scrapy was an appropriate choice due to its efficiency and speed in handling static data on websites. The program extracted relevant data such as the schools' names, locations, UTBK scores, and other relevant information. The extracted data was useful for analyzing and evaluating the schools' academic performance and ranking. The data was saved in CSV format for further processing and analysis.
</div>

<center>
    <br>
    <img src="images/ltmpt-scraper.png"/>
    <img src="images/ltmpt_data.png"/>
    <br>
</center>
---

<center>Â© 2023 Yosafat. Powered by Jekyll and the Minimal Theme.</center>

